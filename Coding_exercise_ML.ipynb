{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONnxHC/78EvSctWogucnB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BotCalvin/BUS-118S/blob/main/Coding_exercise_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1"
      ],
      "metadata": {
        "id": "1AS9Pfe3epmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Data source: \"House Sales in King County, USA\" dataset (commonly hosted on Kaggle)\n",
        "# (house_prices.csv provided for coursework use)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"house_prices.csv\")\n",
        "\n",
        "# --- Fix: map dataset columns to rubric-required fields ---\n",
        "df[\"square_footage\"] = df[\"sqft_living\"]  # square footage\n",
        "# price column already exists as df[\"price\"]\n",
        "\n",
        "# --- Fix: create a categorical \"location\" column: Downtown/Suburb/Rural ---\n",
        "# Seattle downtown reference point (approx.)\n",
        "SEATTLE_LAT, SEATTLE_LON = 47.6062, -122.3321\n",
        "\n",
        "def haversine_miles(lat1, lon1, lat2, lon2):\n",
        "    R = 3958.8  # Earth radius in miles\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return R * c\n",
        "\n",
        "df[\"dist_to_downtown_mi\"] = haversine_miles(df[\"lat\"], df[\"long\"], SEATTLE_LAT, SEATTLE_LON)\n",
        "\n",
        "def categorize_location(d):\n",
        "    if d <= 5:\n",
        "        return \"Downtown\"\n",
        "    elif d <= 20:\n",
        "        return \"Suburb\"\n",
        "    else:\n",
        "        return \"Rural\"\n",
        "\n",
        "df[\"location\"] = df[\"dist_to_downtown_mi\"].apply(categorize_location)\n",
        "\n",
        "# Features and target\n",
        "X = df[[\"square_footage\", \"location\"]]\n",
        "y = df[\"price\"]\n",
        "\n",
        "# Preprocessing: One-hot encode location (drop first category for a clear baseline)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"location\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), [\"location\"]),\n",
        "        (\"square_footage\", \"passthrough\", [\"square_footage\"])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline with preprocessing + regression model\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", LinearRegression())\n",
        "])\n",
        "\n",
        "# Split + train\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediction: 2000 sq ft in Downtown\n",
        "new_house = pd.DataFrame({\"square_footage\": [2000], \"location\": [\"Downtown\"]})\n",
        "predicted_price = model.predict(new_house)\n",
        "\n",
        "print(f\"Predicted price for a 2000 sq ft house in Downtown: ${predicted_price[0]:,.2f}\")\n",
        "\n",
        "# ---- Coefficients + feature names ----\n",
        "ohe = model.named_steps[\"preprocessor\"].named_transformers_[\"location\"]\n",
        "location_feature_names = ohe.get_feature_names_out([\"location\"]).tolist()\n",
        "\n",
        "feature_names = location_feature_names + [\"square_footage\"]\n",
        "coefficients = model.named_steps[\"regressor\"].coef_\n",
        "\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.2f}\")\n",
        "\n",
        "# ---- Plain-English explanation (rubric requirement) ----\n",
        "sqft_coef = coefficients[feature_names.index(\"square_footage\")]\n",
        "\n",
        "print(\"\\nExplanation:\")\n",
        "print(f\"- The square_footage coefficient ({sqft_coef:.2f}) means the predicted price changes by about \"\n",
        "      f\"${sqft_coef:.2f} for every additional 1 sq ft (holding location constant).\")\n",
        "print(\"- The location coefficients show how Suburb/Rural prices shift compared to the baseline category \"\n",
        "      \"(the dropped category from one-hot encoding).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG1FcKMpzySe",
        "outputId": "168f7038-abcc-4e5b-8de5-f0e16aa89d9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price for a 2000 sq ft house in Downtown: $706,043.16\n",
            "\n",
            "Model Coefficients:\n",
            "location_Rural: -366692.02\n",
            "location_Suburb: -200086.82\n",
            "square_footage: 284.40\n",
            "\n",
            "Explanation:\n",
            "- The square_footage coefficient (284.40) means the predicted price changes by about $284.40 for every additional 1 sq ft (holding location constant).\n",
            "- The location coefficients show how Suburb/Rural prices shift compared to the baseline category (the dropped category from one-hot encoding).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "uqugjGVUelH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# -----------------------------\n",
        "# Data & Preprocessing\n",
        "# -----------------------------\n",
        "\n",
        "# Dataset includes customer features and churn label\n",
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Clean TotalCharges (convert from text to numeric)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert churn label Yes/No -> 1/0\n",
        "df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "# Choose features (numerical + categorical)\n",
        "num_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "cat_cols = [\"Contract\", \"InternetService\", \"PaymentMethod\"]\n",
        "\n",
        "X = df[num_cols + cat_cols]\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# Numerical features are scaled using StandardScaler\n",
        "# Categorical features are encoded using OneHotEncoder\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Model & Prediction\n",
        "# -----------------------------\n",
        "\n",
        "# Logistic regression model is trained\n",
        "model = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Split data and train model\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model outputs a churn probability\n",
        "new_customer = pd.DataFrame({\n",
        "    \"tenure\": [12],\n",
        "    \"MonthlyCharges\": [70],\n",
        "    \"TotalCharges\": [800],\n",
        "    \"Contract\": [\"Month-to-month\"],\n",
        "    \"InternetService\": [\"Fiber optic\"],\n",
        "    \"PaymentMethod\": [\"Electronic check\"]\n",
        "})\n",
        "\n",
        "churn_probability = model.predict_proba(new_customer)[0][1]\n",
        "\n",
        "# I used a 0.5 threshold to classify churn\n",
        "threshold = 0.5\n",
        "churn_prediction = 1 if churn_probability >= threshold else 0\n",
        "\n",
        "print(f\"Churn Probability for new customer: {churn_probability:.2f}\")\n",
        "print(f\"Churn Prediction (1 = churn, 0 = no churn): {churn_prediction}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Interpretation\n",
        "# -----------------------------\n",
        "\n",
        "# I explained what the churn probability means\n",
        "# I explained how businesses can use this to reduce churn\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"The churn probability is the model’s estimated likelihood (0 to 1) that the customer will churn.\")\n",
        "print(\"Businesses can use higher churn probabilities to identify at-risk customers and apply retention strategies\")\n",
        "print(\"such as targeted discounts, proactive customer support, or personalized outreach to reduce churn.\")\n",
        "\n",
        "# -----------------------------\n",
        "# Model Coefficients\n",
        "# -----------------------------\n",
        "\n",
        "ohe = model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
        "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
        "\n",
        "feature_names = num_cols + list(cat_feature_names)\n",
        "coefficients = model.named_steps[\"classifier\"].coef_[0]\n",
        "\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for name, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{name}: {coef:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPL3g_cT5wtk",
        "outputId": "f1bf35de-b9b8-4200-b90a-54245c6a5dec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Churn Probability for new customer: 0.65\n",
            "Churn Prediction (1 = churn, 0 = no churn): 1\n",
            "\n",
            "Interpretation:\n",
            "The churn probability is the model’s estimated likelihood (0 to 1) that the customer will churn.\n",
            "Businesses can use higher churn probabilities to identify at-risk customers and apply retention strategies\n",
            "such as targeted discounts, proactive customer support, or personalized outreach to reduce churn.\n",
            "\n",
            "Model Coefficients:\n",
            "tenure: -1.428\n",
            "MonthlyCharges: -0.095\n",
            "TotalCharges: 0.754\n",
            "Contract_Month-to-month: 0.473\n",
            "Contract_One year: -0.428\n",
            "Contract_Two year: -1.139\n",
            "InternetService_DSL: -0.406\n",
            "InternetService_Fiber optic: 0.595\n",
            "InternetService_No: -1.282\n",
            "PaymentMethod_Bank transfer (automatic): -0.311\n",
            "PaymentMethod_Credit card (automatic): -0.433\n",
            "PaymentMethod_Electronic check: 0.096\n",
            "PaymentMethod_Mailed check: -0.444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3"
      ],
      "metadata": {
        "id": "PoE26ApXeeSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Generate sample customer data\n",
        "# -----------------------------\n",
        "data = {\n",
        "    \"annual_spending\": [500, 1200, 300, 1500, 800, 200, 1000, 600, 1300, 400],\n",
        "    \"purchase_frequency\": [5, 12, 3, 15, 8, 2, 10, 6, 13, 4],\n",
        "    \"age\": [25, 34, 45, 28, 52, 36, 41, 29, 47, 33],\n",
        "    \"region\": [\"North\", \"South\", \"West\", \"East\", \"South\", \"North\", \"West\", \"East\", \"South\", \"North\"],\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 1) Preprocess: select numerical features, scale\n",
        "# ---------------------------------------------\n",
        "features = [\"annual_spending\", \"purchase_frequency\", \"age\"]\n",
        "X = df[features].copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 2) Determine optimal K using the elbow method\n",
        "# ---------------------------------------------\n",
        "inertia = []\n",
        "k_values = range(1, 6)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve (saved to file)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(k_values), inertia, marker=\"o\")\n",
        "plt.xlabel(\"Number of Clusters (K)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.xticks(list(k_values))\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"elbow_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 3) Select + justify K (based on elbow)\n",
        "# ---------------------------------------------\n",
        "optimal_k = 3\n",
        "print(f\"Selected K = {optimal_k} based on the elbow plot (see elbow_plot.png).\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 4) Apply K-Means clustering\n",
        "# ---------------------------------------------\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=\"auto\")\n",
        "df[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 5) Analyze clusters (averages + sizes)\n",
        "# ---------------------------------------------\n",
        "print(\"\\nCluster sizes:\")\n",
        "print(df[\"cluster\"].value_counts().sort_index())\n",
        "\n",
        "cluster_summary = df.groupby(\"cluster\")[features].mean().round(2)\n",
        "print(\"\\nCluster Characteristics (Mean Values):\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 6) Marketing strategies for each cluster\n",
        "# ---------------------------------------------\n",
        "print(\"\\nSuggested Marketing Strategies:\")\n",
        "for cluster in range(optimal_k):\n",
        "    print(f\"\\nCluster {cluster} Strategy:\")\n",
        "\n",
        "    if cluster_summary.loc[cluster, \"annual_spending\"] > 1000:\n",
        "        print(\"High-spending customers: Offer exclusive promotions, VIP perks, or loyalty rewards.\")\n",
        "    elif cluster_summary.loc[cluster, \"purchase_frequency\"] > 10:\n",
        "        print(\"Frequent buyers: Provide subscription plans, bundles, or bulk discounts.\")\n",
        "    else:\n",
        "        print(\"Low-engagement customers: Send personalized re-engagement campaigns and targeted offers.\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 7) Save cluster assignments to CSV\n",
        "# ---------------------------------------------\n",
        "df.to_csv(\"customer_segments.csv\", index=False)\n",
        "print(\"\\nSaved cluster results to customer_segments.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yUuDWc1ywNt",
        "outputId": "fd444b01-cd46-4619-e405-facdcc6ec882"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected K = 3 based on the elbow plot (see elbow_plot.png).\n",
            "\n",
            "Cluster sizes:\n",
            "cluster\n",
            "0    1\n",
            "1    5\n",
            "2    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Cluster Characteristics (Mean Values):\n",
            "         annual_spending  purchase_frequency   age\n",
            "cluster                                           \n",
            "0                 1500.0               15.00  28.0\n",
            "1                  400.0                4.00  33.6\n",
            "2                 1075.0               10.75  43.5\n",
            "\n",
            "Suggested Marketing Strategies:\n",
            "\n",
            "Cluster 0 Strategy:\n",
            "High-spending customers: Offer exclusive promotions, VIP perks, or loyalty rewards.\n",
            "\n",
            "Cluster 1 Strategy:\n",
            "Low-engagement customers: Send personalized re-engagement campaigns and targeted offers.\n",
            "\n",
            "Cluster 2 Strategy:\n",
            "High-spending customers: Offer exclusive promotions, VIP perks, or loyalty rewards.\n",
            "\n",
            "Saved cluster results to customer_segments.csv\n"
          ]
        }
      ]
    }
  ]
}